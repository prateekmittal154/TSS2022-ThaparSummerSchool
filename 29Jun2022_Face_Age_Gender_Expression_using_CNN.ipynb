{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "29Jun2022_Face_Age_Gender_Expression_using_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkbnsJc3PRsuMYdYcVPM7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil301290/TSS2022-ThaparSummerSchool/blob/main/29Jun2022_Face_Age_Gender_Expression_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DeepFace - Age, Gender, Expression, Headpose and Recognition**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this lesson, we use the **DeepFace API for Age, Gender, Expression Facial and Recognition. We even use the headpose library to obtain head direction/tilt**. DeepFace is an easy to use python module that provides access to several Facial Detection and Recognition models. It's very simple to use to let's dive in.\n",
        "\n",
        "1. Install the necessary modules and download our files\n",
        "2. Demonstrate facial landmarks\n",
        "3. Obtain Age, Gender, Emotional Expression and Ethnicity using DeepFace\n",
        "4. Perform Facial Similarity\n",
        "5. Perform Facial Recognition\n",
        "\n",
        "\n",
        "**NOTE** Change to High-RAM setting."
      ],
      "metadata": {
        "id": "9uc6O9Vu1-iY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Install the necessary modules and download our files**"
      ],
      "metadata": {
        "id": "_sXenPrT2P4V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovPGeyz6zrWp"
      },
      "outputs": [],
      "source": [
        "!pip install deepface\n",
        "!pip install dlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define our imshow function**"
      ],
      "metadata": {
        "id": "2FpUdugs2Uwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some imports and our image viewing function\n",
        "import dlib\n",
        "import tarfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Define our imshow function \n",
        "def imshow(title = \"Image\", image = None, size = 6):\n",
        "    w, h = image.shape[0], image.shape[1]\n",
        "    aspect_ratio = w/h\n",
        "    plt.figure(figsize=(size * aspect_ratio,size))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CVhSGned2RuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download facial landmarks\n",
        "!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/shape_predictor_68_face_landmarks.dat"
      ],
      "metadata": {
        "id": "OVtF2GJE2W7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Getting Test Images and Test Pic"
      ],
      "metadata": {
        "id": "yBR6OfsL4Q10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "CYbROYTO8kmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/TSS2022_Datasets/face_recognition.zip'"
      ],
      "metadata": {
        "id": "KYPZYW2v4Zn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Demonstrate facial landmarks**"
      ],
      "metadata": {
        "id": "9JHIGjiT3x9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import face_utils\n",
        "\n",
        "p = \"shape_predictor_68_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(p)\n",
        "\n",
        "image = cv2.imread('sahil1.JPG')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "# Get faces \n",
        "rects = detector(gray, 0)\n",
        "\n",
        "# For each detected face, find the landmark.\n",
        "for (i, rect) in enumerate(rects):\n",
        "    # Make the prediction and transfom it to numpy array\n",
        "    shape = predictor(gray, rect)\n",
        "    shape = face_utils.shape_to_np(shape)\n",
        "    (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    # Draw on our image, all the finded cordinate points (x,y) \n",
        "    for (x, y) in shape:\n",
        "        cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
        "\n",
        "# Show the image\n",
        "imshow(\"Output\", image)"
      ],
      "metadata": {
        "id": "TpEa7z692ZHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Obtain Age, Gender, Emotional Expression and Ethnicity using DeepFace**\n",
        "\n",
        "**Download our models**"
      ],
      "metadata": {
        "id": "L0Hmu2eb4ACI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1Id32-d-nS9BooBLLkw1PQhvLWWAukCsq\n",
        "!gdown --id 1txWignSWdELl8cWdZHYqIlSE2ZRjI8WI\n",
        "!gdown --id 1d_tQRWjvQ5i4lZyUfFEfRj7LzXWXseBY\n",
        "!gdown --id 1kWp2CVg_xTIFqdZAwfN_86A3grim9NyI\n",
        "\n",
        "!mv facial_expression_model_weights.zip /root/.deepface/weights/facial_expression_model_weights.zip\n",
        "!mv age_model_weights.h5 /root/.deepface/weights/age_model_weights.h5\n",
        "!mv gender_model_weights.h5 /root/.deepface/weights/gender_model_weights.h5\n",
        "!mv race_model_single_batch.zip /root/.deepface/weights/race_model_single_batch.zip"
      ],
      "metadata": {
        "id": "IRih6d0i34Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace"
      ],
      "metadata": {
        "id": "1Bp2dzoG4HER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = DeepFace.analyze(img_path =  \"./face_recognition/people/sahil.jpg\", actions = ['age', 'gender', 'race', 'emotion'])\n",
        "print(obj[\"age\"],\" years old \",obj[\"dominant_race\"],\" \",obj[\"dominant_emotion\"],\" \", obj[\"gender\"])"
      ],
      "metadata": {
        "id": "7CIbstHc4jzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import pprint\n",
        "\n",
        "img_path = \"./face_recognition/people/sahil.jpg\"\n",
        "image = cv2.imread(img_path)\n",
        "\n",
        "obj = DeepFace.analyze(img_path = img_path,\n",
        "                       actions = ['age', 'gender', 'race', 'emotion'])\n",
        "imshow(\"Face Analysis\", image)\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(obj)"
      ],
      "metadata": {
        "id": "9Y4PoRPW42Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Create a simple function to display our results on the image**"
      ],
      "metadata": {
        "id": "i_WGsrce5Zhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def drawFace(img_path, obj):\n",
        "  image = cv2.imread(img_path)\n",
        "  x = obj['region']['x'] \n",
        "  y = obj['region']['y'] \n",
        "  h = obj['region']['h'] \n",
        "  w = obj['region']['w'] \n",
        "  age = obj['age']\n",
        "  gender = obj['gender']\n",
        "  gender = 'F' if gender == 'Woman' else 'M'\n",
        "  dominant_emotion = obj['dominant_emotion']\n",
        "  dominant_race = obj['dominant_race']\n",
        "  dominant_emotion = obj['dominant_emotion']\n",
        "  description = f'{age}{gender} - {dominant_emotion}'\n",
        "  cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "  cv2.putText(image, description, (x,y-10) , cv2.FONT_HERSHEY_PLAIN,2, (0,255,0), 3)\n",
        "  cv2.putText(image, dominant_race, (x,y+h+30) , cv2.FONT_HERSHEY_PLAIN,2, (0,255,0), 3)\n",
        "  imshow(\"Face Analysis\", image)"
      ],
      "metadata": {
        "id": "ymdBG_qI5QUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Test on another image**"
      ],
      "metadata": {
        "id": "XbC2WX6x5k10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import pprint\n",
        "\n",
        "img_path = \"/content/sahil1.JPG\"\n",
        "image = cv2.imread(img_path)\n",
        "obj = DeepFace.analyze(img_path = img_path, enforce_detection=False, actions = ['age', 'gender', 'race', 'emotion'])\n",
        "drawFace(img_path, obj)\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(obj)"
      ],
      "metadata": {
        "id": "kE5wJ1JM5jJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Change backends of face detection**"
      ],
      "metadata": {
        "id": "_EK47xS66QPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "\n",
        "# backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface']\n",
        "\n",
        "img_path = \"./sahil1.JPG\"\n",
        "image = cv2.imread(img_path)\n",
        "obj = DeepFace.analyze(img_path = \"./sahil1.JPG\", actions = ['age', 'gender', 'race', 'emotion'], detector_backend = 'ssd')\n",
        "drawFace(img_path, obj)\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(obj)"
      ],
      "metadata": {
        "id": "Wrqn2m215tGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Perform Facial Similarity**"
      ],
      "metadata": {
        "id": "0LQDkRCe6qGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result  = DeepFace.verify(\"./face_recognition/people/sahil.jpg\", \"./sahil1.JPG\", enforce_detection=False)\n",
        "print(\"Is verified: \", result[\"verified\"])\n",
        "result"
      ],
      "metadata": {
        "id": "rdRwt-3k6cFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **We can even use different Distance Metrics**"
      ],
      "metadata": {
        "id": "x8A2LEm47wHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
        "\n",
        "result  = DeepFace.verify(\"./face_recognition/people/sahil.jpg\", \"./sahil1.JPG\", enforce_detection=False, distance_metric = 'euclidean')\n",
        "print(\"Is verified: \", result[\"verified\"])\n",
        "result"
      ],
      "metadata": {
        "id": "2ebNiA0s7Bag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
        "\n",
        "result  = DeepFace.verify(\"./face_recognition/people/sahil.jpg\", \"./sahil1.JPG\", enforce_detection=False, distance_metric = 'euclidean_l2')\n",
        "print(\"Is verified: \", result[\"verified\"])\n",
        "result"
      ],
      "metadata": {
        "id": "HoiUPh7P8Gpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download models as the existing DeepFace downloader has stopped working**"
      ],
      "metadata": {
        "id": "hTnRGj1A8T88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1OdJNKL85CCYStVi9XtJRpHhXo2FU6Gf1\n",
        "!gdown --id 1GWIuvW3Vm3wMpGGEyTT7sU-c1cVWZIEc\n",
        "!mv vgg_face_weights.h5 /root/.deepface/weights/vgg_face_weights.h5\n",
        "!mv facenet_weights.h5 /root/.deepface/weights/facenet_weights.h5"
      ],
      "metadata": {
        "id": "rHdaaSgk8KJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Perform Facial Recognition**"
      ],
      "metadata": {
        "id": "NauxQE198YbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import pandas as pd\n",
        "\n",
        "df = DeepFace.find(img_path = \"./face_recognition/training_faces/Nidia_1.jpg\", db_path = './face_recognition/training_faces/', detector_backend = 'ssd')\n",
        "df"
      ],
      "metadata": {
        "id": "2hNzV2fs8WpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **We can even try a few different models**"
      ],
      "metadata": {
        "id": "ZS2_RT--8_3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import pandas as pd\n",
        "\n",
        "dfs = []\n",
        "models = [\"VGG-Face\", \"Facenet\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
        "\n",
        "for model in models:\n",
        "   df = DeepFace.find(img_path = \"./face_recognition/training_faces/Nidia_1.jpg\", db_path = './face_recognition/training_faces/', model_name = model,  detector_backend = 'ssd')\n",
        "   df['model'] = model\n",
        "   dfs.append(df)\n",
        "\n",
        "pd.concat(dfs)"
      ],
      "metadata": {
        "id": "upvmQS0I82we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow('1', cv2.imread('./face_recognition/training_faces/Nidia_1.jpg'))\n",
        "imshow('1', cv2.imread('./face_recognition/training_faces/Nidia_5.jpg'))"
      ],
      "metadata": {
        "id": "CBMT5dDL9GzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of Code"
      ],
      "metadata": {
        "id": "W9jgCbSW94Ci"
      }
    }
  ]
}