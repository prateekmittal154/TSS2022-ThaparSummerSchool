{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil301290/TSS2022-ThaparSummerSchool/blob/main/29Jun2022_CatsvsDogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Cats vs Dogs Classification**\n",
        "\n",
        "###**1.1 Import all the important libraries**"
      ],
      "metadata": {
        "id": "xqNjP62dtxFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgEyK0vyZeNX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.2 Download and upzip the raw data**"
      ],
      "metadata": {
        "id": "uQ9TeKY3uF-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmUwihUeZrh5"
      },
      "outputs": [],
      "source": [
        "!gdown --id 1Dvw0UpvItjig0JbnzbTgYKB-ibMrXdxk\n",
        "!unzip -q dogs-vs-cats.zip\n",
        "!unzip -q train.zip\n",
        "!unzip -q test1.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.3 Define our images sizes**"
      ],
      "metadata": {
        "id": "s5_6NEutuomF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3L0uEjRZscQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_WIDTH = 60\n",
        "IMAGE_HEIGHT = 60\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.4 Data Preprocessing**"
      ],
      "metadata": {
        "id": "4g-peEEguyA9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vbi-PEoZ30i"
      },
      "source": [
        "#### **1.4.1 Loading our data and it's labels into a dataframe**\n",
        "\n",
        "There are many ways we can do this, this way is relatively simple to follow.\n",
        "\n",
        "`dog.1034234.jpg`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaGZFAXZZ1c9"
      },
      "outputs": [],
      "source": [
        "filenames = os.listdir(\"./train\")\n",
        "\n",
        "categories = []\n",
        "\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'class': categories\n",
        "})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI5I-Qn2Z91h"
      },
      "source": [
        "#### **1.4.2 Check the counts in each class**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()"
      ],
      "metadata": {
        "id": "5nPkKjXS19-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohzu06cJZ6zG"
      },
      "outputs": [],
      "source": [
        "df['class'].value_counts().plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOuUHnZGaCL3"
      },
      "source": [
        "#### **1.4.3 View a sample image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1d_BNkZZ_5r"
      },
      "outputs": [],
      "source": [
        "sample = random.choice(filenames)\n",
        "image = load_img(\"./train/\" + sample)\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omzpB576aKFb"
      },
      "source": [
        "## **2. Create our CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyXyJQQCaEj8"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lauxCU5QaRNr"
      },
      "source": [
        "## **3. Create our Data Generators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEAkzw4zaOIH"
      },
      "outputs": [],
      "source": [
        "df[\"class\"] = df[\"class\"].replace({0: 'cat', 1: 'dog'}) \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GxIMtMXaVM8"
      },
      "source": [
        "#### **3.1 Split our dataset using train_test_split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWmTkONMaTKB"
      },
      "outputs": [],
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=7)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FBGbOgqaXOF"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl-dg-O8aY36"
      },
      "outputs": [],
      "source": [
        "validate_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch_size** determines the number of samples in each mini batch. Its maximum is the number of all samples, which makes gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but iterations are slower. Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around. batch_size allows to adjust between the two extremes: accurate gradient direction and fast iteration. Also, the maximum value for batch_size may be limited if your model + data set does not fit into the available (GPU) memory.\n",
        "\n",
        "**steps_per_epoch** the number of batch iterations before a training epoch is considered finished. If you have a training set of fixed size you can ignore it but it may be useful if you have a huge data set or if you are generating random data augmentations on the fly, i.e. if your training set has a (generated) infinite size. If you have the time to go through your whole training data set I recommend to skip this parameter.\n",
        "\n",
        "**validation_steps** similar to steps_per_epoch but on the validation data set instead on the training data. If you have the time to go through your whole validation data set I recommend to skip this parameter."
      ],
      "metadata": {
        "id": "obLebYz_1Trk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WTSUqbLac2Q"
      },
      "source": [
        "#### **3.2 Create our Training Data Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PKqEHIAaanc"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    \"./train/\", \n",
        "    x_col = 'filename',\n",
        "    y_col = 'class',\n",
        "    target_size = IMAGE_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1GWIw0EajP5"
      },
      "source": [
        "#### **3.3 Create our Validation Data Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5JJncz8aety"
      },
      "outputs": [],
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    \"./train/\", \n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvIlzJDcanMM"
      },
      "source": [
        "#### **3.4 Creating an example Data Generator to load just a single image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqcbKzGmalPY"
      },
      "outputs": [],
      "source": [
        "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
        "\n",
        "example_generator = train_datagen.flow_from_dataframe(\n",
        "    example_df, \n",
        "    \"./train/\", \n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BONF6uBUarya"
      },
      "source": [
        "#### **3.5 Preview that image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntF_mtY9apcr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "for X_batch, Y_batch in example_generator:\n",
        "    image = X_batch[0]\n",
        "    plt.imshow(image)\n",
        "    break\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRof3aHgaxUg"
      },
      "source": [
        "## **4. Start Training Our Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsKXb8Rtaut7"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator, \n",
        "    epochs = epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 5000//batch_size,\n",
        "    steps_per_epoch = 20000//batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.1 Saving the model**"
      ],
      "metadata": {
        "id": "_v4hM5Slxo25"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwI4ZXLhazyD"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"cats_vs_dogs_5_epochs.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.2 View Training and Validation graphs for loss and accuracy**"
      ],
      "metadata": {
        "id": "2WqCoRK_xwtn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMxxXJ_pa2bi"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, epochs, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, epochs, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWTzT6lXa6hI"
      },
      "source": [
        "#### **4.3 Get the predictions for our validation images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7u5hlAja4Tq"
      },
      "outputs": [],
      "source": [
        "predict = model.predict_generator(validation_generator, steps = np.ceil(5000/batch_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkuip_kia_B2"
      },
      "source": [
        "#### **4.4 Add it to our dataframe for easy viewing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tf9Cu73a8h0"
      },
      "outputs": [],
      "source": [
        "validate_df['predicted'] = np.argmax(predict, axis=-1)\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "validate_df['predicted'] = validate_df['predicted'].replace(label_map)\n",
        "validate_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpnaFbERbDhq"
      },
      "source": [
        "## **5. Inference on a batch of images from our validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_ZdEJ5pbBbz"
      },
      "outputs": [],
      "source": [
        "sample_test = validate_df.head(18)\n",
        "sample_test.head()\n",
        "\n",
        "plt.figure(figsize=(12, 24))\n",
        "\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['predicted']\n",
        "    img = load_img(\"./train/\"+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Callbacks function**"
      ],
      "metadata": {
        "id": "bkNuXVJby7-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **6.1 Import callbacks**"
      ],
      "metadata": {
        "id": "ilThoanp34UV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj7N0rR3bF2Y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **6.2 Defining Checkpoint and Earlystop conditions**"
      ],
      "metadata": {
        "id": "QzUql9iO3_oj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i4z0vxhbK6V"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "checkpoint = ModelCheckpoint(checkpoint_filepath,\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', # value being monitored for improvement\n",
        "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
        "                          patience = 5, #Number of epochs we wait before stopping \n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True) #keeps the best weigths once stopped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qV--AFfbQXJ"
      },
      "source": [
        "#### **6.3 Reducing our learning Rate on Plateau**\n",
        "\n",
        "We can avoid having our oscillate around the global minimum by attempting to reduce the Learn Rate by a certain fact. If no improvement is seen in our monitored metric (val_loss typically), we wait a certain number of epochs (patience) then this callback reduces the learning rate by a factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHKOeov1bNG9"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **6.4 Defining Callback list**"
      ],
      "metadata": {
        "id": "KskcjLeR4Nti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17qjkAVJbSsO"
      },
      "outputs": [],
      "source": [
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **6.5 Stopping training early based on callbacks**"
      ],
      "metadata": {
        "id": "53n-BVXE4SIm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEIJ2_eabU4m"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator, \n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 5000//batch_size,\n",
        "    steps_per_epoch = 20000//batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###End of Code"
      ],
      "metadata": {
        "id": "0lhPqCXU0Imr"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "29Jun2022_CatsvsDogs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTP/2vDOn1xXwoZhGxROFD",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}